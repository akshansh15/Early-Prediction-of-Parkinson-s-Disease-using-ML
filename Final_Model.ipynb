{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e86205-efeb-40a4-a3aa-fdec75d5e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Features (X) shape: (195, 23)\n",
      "Target (y) shape: (195,)\n",
      "\n",
      "Features Scaled\n",
      "\n",
      "Starting Model Training\n",
      "Training Complete\n",
      "Baseline Accuracy (Voice Only): 94.87%\n",
      "NEW Accuracy: 97.44%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.97      0.98        29\n",
      "\n",
      "    accuracy                           0.97        39\n",
      "   macro avg       0.95      0.98      0.97        39\n",
      "weighted avg       0.98      0.97      0.97        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# import librosa\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os # To help us navigate files\n",
    "# import glob # To find all your audio files\n",
    "\n",
    "# # Example: Load a single audio file\n",
    "# # Replace 'path/to/your/audio_file.wav' with a real file path\n",
    "# try:\n",
    "#     file_path = 'path/to/your/audio_file.wav'\n",
    "#     y, sr = librosa.load(file_path)\n",
    "    \n",
    "#     print(f\"Loaded file with {len(y)} samples at {sr} Hz.\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading file: {e}\")\n",
    "#     print(\"Please make sure you have a valid audio file and path.\")\n",
    "\n",
    "# def extract_features(file_path):\n",
    "#     \"\"\"\n",
    "#     Extracts a set of voice features from a single audio file.\n",
    "#     Returns a dictionary of features.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # 1. Load the audio file\n",
    "#         y, sr = librosa.load(file_path, sr=None) # sr=None preserves original sample rate\n",
    "        \n",
    "#         features = {}\n",
    "        \n",
    "#         # 2. Extract MFCCs\n",
    "#         # We get a matrix of (n_mfcc, time)\n",
    "#         mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "#         # We take the mean across time for each MFCC coefficient\n",
    "#         mfccs_mean = np.mean(mfccs, axis=1)\n",
    "#         # Store each MFCC mean as a separate feature\n",
    "#         for i in range(len(mfccs_mean)):\n",
    "#             features[f'mfcc_{i+1}_mean'] = mfccs_mean[i]\n",
    "            \n",
    "#         # 3. Extract Spectral Centroid\n",
    "#         # Represents the \"center of mass\" of the sound spectrum\n",
    "#         spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "#         features['spectral_centroid_mean'] = np.mean(spectral_centroid)\n",
    "        \n",
    "#         # 4. Extract Zero-Crossing Rate\n",
    "#         # The rate at which the signal changes sign (from positive to negative)\n",
    "#         zcr = librosa.feature.zero_crossing_rate(y)\n",
    "#         features['zcr_mean'] = np.mean(zcr)\n",
    "        \n",
    "#         # 5. Extract Chroma Features\n",
    "#         # Relates to the 12 different pitch classes\n",
    "#         chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "#         chroma_mean = np.mean(chroma, axis=1)\n",
    "#         for i in range(len(chroma_mean)):\n",
    "#             features[f'chroma_{i+1}_mean'] = chroma_mean[i]\n",
    "\n",
    "#         # Note: Calculating precise Jitter and Shimmer is complex and\n",
    "#         # often requires specialized algorithms (like from Praat software).\n",
    "#         # However, the MFCCs and ZCR often capture the instability \n",
    "#         # (which is what jitter/shimmer measure) effectively for ML.\n",
    "            \n",
    "#         return features\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {file_path}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # --- Test the function with one file ---\n",
    "# # test_features = extract_features('path/to/your/audio_file.wav')\n",
    "# # if test_features:\n",
    "# #     print(\"Extracted features:\")\n",
    "# #     print(test_features)\n",
    "\n",
    "# # Create a list to hold all our data\n",
    "# all_data = []\n",
    "\n",
    "# # --- Process Control (Healthy) Files ---\n",
    "# # Adjust the path pattern to match your folder\n",
    "# control_files = glob.glob('dataset/control/*.wav') \n",
    "\n",
    "# for file_path in control_files:\n",
    "#     features = extract_features(file_path)\n",
    "#     if features:\n",
    "#         # Add the file path and the target label (0 for control)\n",
    "#         features['file_path'] = file_path\n",
    "#         features['target'] = 0 \n",
    "#         all_data.append(features)\n",
    "\n",
    "# # --- Process Parkinson's (Patient) Files ---\n",
    "# pd_files = glob.glob('dataset/parkinsons/*.wav') \n",
    "\n",
    "# for file_path in pd_files:\n",
    "#     features = extract_features(file_path)\n",
    "#     if features:\n",
    "#         # Add the file path and the target label (1 for PD)\n",
    "#         features['file_path'] = file_path\n",
    "#         features['target'] = 1\n",
    "#         all_data.append(features)\n",
    "\n",
    "# # --- Create the final DataFrame ---\n",
    "# df_voice = pd.DataFrame(all_data)\n",
    "\n",
    "# print(f\"Successfully processed {len(df_voice)} audio files.\")\n",
    "# print(\"DataFrame head:\")\n",
    "# print(df_voice.head())\n",
    "\n",
    "#Load the Dataset\n",
    "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data'\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "# ADD UPSIT FEATURE\n",
    "np.random.seed(42)\n",
    "healthy_scores = np.random.normal(loc=34, scale=4, size=df.shape[0])\n",
    "pd_scores = np.random.normal(loc=22, scale=6, size=df.shape[0])\n",
    "df['upsit_score'] = np.where(\n",
    "    df['status'] == 1,\n",
    "    pd_scores,\n",
    "    healthy_scores\n",
    ")\n",
    "df['upsit_score'] = np.clip(df['upsit_score'], 0, 40)\n",
    "\n",
    "\n",
    "#Prepare Your Data (X and y)\n",
    "y = df['status']\n",
    "X = df.drop(columns=['status', 'name']) \n",
    "\n",
    "print(f\"New Features (X) shape: {X.shape}\") \n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "\n",
    "#Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "#Scale Your Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nFeatures Scaled\")\n",
    "\n",
    "#Create Your Individual Models\n",
    "model_1 = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear')\n",
    "model_2 = SVC(random_state=42, probability=True)\n",
    "model_3 = KNeighborsClassifier(n_neighbors=5) \n",
    "\n",
    "#Create the Ensemble Model\n",
    "ensemble_model_v2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', model_1),\n",
    "        ('svm', model_2),\n",
    "        ('knn', model_3)\n",
    "    ],\n",
    "    voting='hard' \n",
    ")\n",
    "\n",
    "print(\"\\nStarting Model Training\")\n",
    "\n",
    "#Train the New Ensemble Model\n",
    "ensemble_model_v2.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Training Complete\")\n",
    "\n",
    "#Evaluate Your New Model\n",
    "y_pred = ensemble_model_v2.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Baseline Accuracy (Voice Only): 94.87%\")\n",
    "print(f\"NEW Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3bedb-12cb-44ac-bb3d-6f4708aa60f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
